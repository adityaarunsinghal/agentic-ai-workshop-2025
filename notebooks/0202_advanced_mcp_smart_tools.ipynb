{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e4a7f4a3",
      "metadata": {},
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "# NYU Agentic AI Workshop - Session 2\n",
        "\n",
        "## Advanced MCP Features and Agentic AI Survey\n",
        "\n",
        "### Part 2: Making \"smart\" tools to help clients preserve context\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeb830c9",
      "metadata": {},
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "<img src=\"https://github.com/adityaarunsinghal/agentic-ai-workshop-2025/blob/main/notebooks/media/mcp_restaurant_11_server_isolation.png?raw=true\" width=\"500\" alt=\"mcp_restaurant_11_server_isolation\">\n",
        "<!-- <img src=\"https://github.com/adityaarunsinghal/agentic-ai-workshop-2025/blob/main/notebooks/media/mcp_restaurant_11_server_isolation.png?raw=true\" width=\"500\" alt=\"mcp_restaurant_11_server_isolation\"> -->\n",
        "\n",
        "### The different kitchens never learn each others' secrets\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/adityaarunsinghal/agentic-ai-workshop-2025/blob/main/notebooks/media/mcp_restaurant_14_json_rpc.png?raw=true\" width=\"500\" alt=\"mcp_restaurant_14_json_rpc\">\n",
        "<!-- <img src=\"https://github.com/adityaarunsinghal/agentic-ai-workshop-2025/blob/main/notebooks/media/mcp_restaurant_14_json_rpc.png?raw=true\" width=\"500\" alt=\"mcp_restaurant_14_json_rpc\"> -->\n",
        "\n",
        "### All conversations follow a standard format\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b145b799",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… All imports successful!\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "import os\n",
        "import sys\n",
        "from contextlib import asynccontextmanager\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Dict, List\n",
        "\n",
        "import nest_asyncio\n",
        "from dotenv import load_dotenv\n",
        "from fastmcp import Context, FastMCP\n",
        "\n",
        "# Load environment\n",
        "env_path = Path.cwd().parent / \".env\"\n",
        "load_dotenv(env_path)\n",
        "\n",
        "# Add server to path\n",
        "sys.path.insert(0, str(Path.cwd().parent / \"src\" / \"server\"))\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Service imports\n",
        "from src.server.config.settings import get_settings\n",
        "from src.server.services.article_memory_v2 import ArticleMemoryService\n",
        "from src.server.services.email_service import EmailService\n",
        "from src.server.services.http_client import HackerNewsClient, fetch_content\n",
        "from src.server.services.interests_file import InterestsFileService\n",
        "from src.server.services.newspaper_service import NewspaperService\n",
        "\n",
        "print(\"âœ… All imports successful!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5fe81803",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# APPLICATION CONTEXT\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class AppContext:\n",
        "    \"\"\"Application context with all services.\"\"\"\n",
        "\n",
        "    hn_client: HackerNewsClient\n",
        "    interests_service: InterestsFileService\n",
        "    article_memory: ArticleMemoryService\n",
        "    newspaper_service: NewspaperService\n",
        "    email_service: EmailService\n",
        "    settings: object\n",
        "\n",
        "\n",
        "@asynccontextmanager\n",
        "async def app_lifespan(mcp: FastMCP):\n",
        "    \"\"\"Initialize all services for the newspaper agent.\"\"\"\n",
        "    print(\"ðŸš€ Starting Advanced Newspaper Agent MCP Server\")\n",
        "\n",
        "    settings = get_settings()\n",
        "    settings.data_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Initialize services\n",
        "    hn_client = HackerNewsClient()\n",
        "    interests_service = InterestsFileService(settings.data_dir)\n",
        "    article_memory = ArticleMemoryService()\n",
        "    article_memory.initialize(settings.data_dir / \"chromadb\")\n",
        "    newspaper_service = NewspaperService(settings.data_dir)\n",
        "\n",
        "    # Email service\n",
        "    email_service = EmailService(\n",
        "        {\n",
        "            \"server\": \"smtp.gmail.com\",\n",
        "            \"port\": 465,\n",
        "            \"use_tls\": False,\n",
        "            \"use_ssl\": True,\n",
        "            \"username\": os.getenv(\"MCP_SMTP_FROM_EMAIL\", \"\"),\n",
        "            \"password\": os.getenv(\"MCP_SMTP_PASSWORD\", \"\"),\n",
        "            \"from_email\": os.getenv(\"MCP_SMTP_FROM_EMAIL\", \"\"),\n",
        "            \"from_name\": \"AI Newspaper Agent\",\n",
        "        }\n",
        "    )\n",
        "\n",
        "    print(\"âœ… All services initialized!\")\n",
        "\n",
        "    try:\n",
        "        yield AppContext(\n",
        "            hn_client=hn_client,\n",
        "            interests_service=interests_service,\n",
        "            article_memory=article_memory,\n",
        "            newspaper_service=newspaper_service,\n",
        "            email_service=email_service,\n",
        "            settings=settings,\n",
        "        )\n",
        "    finally:\n",
        "        print(\"ðŸ‘‹ Shutting down MCP Server\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d36c5892",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# MCP SERVER\n",
        "# ============================================================================\n",
        "\n",
        "mcp = FastMCP(\n",
        "    name=\"advanced-newspaper-agent\",\n",
        "    instructions=\"\"\"Advanced newspaper creation system with intelligent content discovery and composition.\n",
        "\n",
        "AGENT ROLE: Strategic Editor\n",
        "- Decide WHICH stories to cover\n",
        "- Choose editorial ANGLE and DEPTH\n",
        "- Control STRUCTURE and POLISH\n",
        "- Delegate tactical execution to smart tools\n",
        "\n",
        "SMART FEATURES:\n",
        "- Content discovery automatically stores in ChromaDB with clean content IDs\n",
        "- Context (interests, past coverage) flows automatically via sampling\n",
        "- One tool call adds multiple articles with full formatting\n",
        "- Elicitation enables interactive workflows\n",
        "- Quality validation enforces standards\n",
        "\n",
        "CORE WORKFLOW:\n",
        "1. discover_stories() â†’ Get enriched story list with content IDs\n",
        "2. quick_look() â†’ Preview any content by ID\n",
        "3. create_newspaper() â†’ Start with smart defaults\n",
        "4. add_content_cluster() â†’ Add multiple articles in one call\n",
        "5. Polish with section/article controls\n",
        "6. validate_and_finalize() â†’ Enforce quality standards\n",
        "7. publish_newspaper() â†’ Deliver\n",
        "\n",
        "Current date: {datetime.now().strftime('%A, %B %d, %Y')}\"\"\",\n",
        "    lifespan=app_lifespan,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "529eec34",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# RESOURCES\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "@mcp.resource(\"file://interests.md\")\n",
        "async def get_interests_resource(ctx: Context = None) -> str:\n",
        "    \"\"\"User's interests - topics, sources, preferences.\n",
        "\n",
        "    Annotations: High priority, for assistant consumption.\"\"\"\n",
        "    interests_service = ctx.request_context.lifespan_context.interests_service\n",
        "    interests = interests_service.read_interests()\n",
        "\n",
        "    content = \"# User Interests\\n\\n\"\n",
        "    content += f\"**Last Updated:** {interests.get('last_updated', 'Unknown')}\\n\\n\"\n",
        "\n",
        "    if interests.get(\"topics\"):\n",
        "        content += \"## Topics\\n\"\n",
        "        for topic in interests[\"topics\"]:\n",
        "            content += f\"- {topic}\\n\"\n",
        "        content += \"\\n\"\n",
        "\n",
        "    if interests.get(\"sources\"):\n",
        "        content += \"## Preferred Sources\\n\"\n",
        "        for source in interests[\"sources\"]:\n",
        "            content += f\"- {source}\\n\"\n",
        "        content += \"\\n\"\n",
        "\n",
        "    content += f\"## Summary Style\\n- {interests.get('style', 'detailed')}\\n\\n\"\n",
        "\n",
        "    if interests.get(\"notes\"):\n",
        "        content += \"## Notes\\n\"\n",
        "        for note in interests[\"notes\"]:\n",
        "            content += f\"- {note}\\n\"\n",
        "\n",
        "    return content\n",
        "\n",
        "\n",
        "@mcp.resource(\"memory://context-summary\")\n",
        "async def get_context_summary(ctx: Context = None) -> str:\n",
        "    \"\"\"Live summary of archive - recent newspapers, trending topics, coverage gaps.\n",
        "\n",
        "    Annotations: High priority, refreshes every 5 minutes.\"\"\"\n",
        "    article_memory = ctx.request_context.lifespan_context.article_memory\n",
        "    interests_service = ctx.request_context.lifespan_context.interests_service\n",
        "\n",
        "    # Get stats\n",
        "    stats = article_memory.get_context_summary()\n",
        "    interests = interests_service.read_interests()\n",
        "    user_topics = set(interests.get(\"topics\", []))\n",
        "\n",
        "    content = \"# Archive Context Summary\\n\\n\"\n",
        "\n",
        "    content += \"## Recent Activity\\n\"\n",
        "    content += f\"- **Total Articles Stored:** {stats['total_articles']}\\n\"\n",
        "    content += f\"- **Newspapers Created:** {stats['total_newspapers']}\\n\"\n",
        "    content += f\"- **Last Article Added:** {stats['last_article_date']}\\n\\n\"\n",
        "\n",
        "    if stats[\"recent_newspapers\"]:\n",
        "        content += \"## Recent Newspapers (Last 5)\\n\"\n",
        "        for paper in stats[\"recent_newspapers\"]:\n",
        "            content += f\"- **{paper['title']}** ({paper['date']}) - {paper['reading_time']}min, {paper['article_count']} articles\\n\"\n",
        "        content += \"\\n\"\n",
        "\n",
        "    if stats[\"trending_topics\"]:\n",
        "        content += \"## Trending Topics (Most Covered)\\n\"\n",
        "        for topic, count in stats[\"trending_topics\"]:\n",
        "            content += f\"- {topic}: {count} articles\\n\"\n",
        "        content += \"\\n\"\n",
        "\n",
        "    # Calculate coverage gaps\n",
        "    covered_topics = {topic for topic, _ in stats[\"trending_topics\"]}\n",
        "    gaps = user_topics - covered_topics\n",
        "\n",
        "    if gaps:\n",
        "        content += \"## Coverage Gaps (Interests Not Recently Covered)\\n\"\n",
        "        for gap in gaps:\n",
        "            content += f\"- {gap}\\n\"\n",
        "        content += \"\\n\"\n",
        "\n",
        "    return content\n",
        "\n",
        "\n",
        "@mcp.resource(\"memory://articles/{topic}\")\n",
        "async def get_articles_by_topic(topic: str, ctx: Context = None) -> str:\n",
        "    \"\"\"Dynamic resource template - search articles by topic.\n",
        "\n",
        "    Example: memory://articles/distributed-systems\n",
        "    Returns semantic search results for that topic.\"\"\"\n",
        "    article_memory = ctx.request_context.lifespan_context.article_memory\n",
        "\n",
        "    articles = article_memory.search_articles(query=topic, limit=10)\n",
        "\n",
        "    if not articles:\n",
        "        return f\"# No articles found for '{topic}'\\n\\nTry broader search terms or different topics.\"\n",
        "\n",
        "    content = f\"# Articles about '{topic}' ({len(articles)} found)\\n\\n\"\n",
        "\n",
        "    for i, article in enumerate(articles, 1):\n",
        "        content += f\"## {i}. {article['title']}\\n\"\n",
        "        content += f\"**Content ID:** {article.get('content_id', 'unknown')}\\n\"\n",
        "        content += f\"**Similarity:** {article['similarity']:.1%} | \"\n",
        "        content += f\"**Source:** {article['source']} | \"\n",
        "        content += f\"**Reading Time:** {article.get('reading_time', '?')} min\\n\"\n",
        "        if article[\"topics\"]:\n",
        "            content += f\"**Topics:** {', '.join(article['topics'])}\\n\"\n",
        "        content += f\"**URL:** {article['url']}\\n\\n\"\n",
        "        if article.get(\"summary\"):\n",
        "            content += f\"{article['summary']}\\n\\n\"\n",
        "        content += \"---\\n\\n\"\n",
        "\n",
        "    return content\n",
        "\n",
        "\n",
        "@mcp.resource(\"memory://newspapers/recent\")\n",
        "async def get_recent_newspapers(ctx: Context = None) -> str:\n",
        "    \"\"\"Recent newspapers for structural reference and avoiding repetition.\n",
        "\n",
        "    Shows last 5 newspapers with structure, topics, and metadata.\"\"\"\n",
        "    article_memory = ctx.request_context.lifespan_context.article_memory\n",
        "\n",
        "    newspapers = article_memory.search_newspapers(days_back=30)[:5]\n",
        "\n",
        "    if not newspapers:\n",
        "        return \"# No Recent Newspapers\\n\\nThis is your first newspaper!\"\n",
        "\n",
        "    content = f\"# Recent Newspapers ({len(newspapers)})\\n\\n\"\n",
        "\n",
        "    for paper in newspapers:\n",
        "        content += f\"## {paper['title']}\\n\"\n",
        "        content += f\"**ID:** {paper['newspaper_id']}\\n\"\n",
        "        content += f\"**Date:** {paper['timestamp'][:10]}\\n\"\n",
        "        content += f\"**Type:** {paper['edition_type']} | \"\n",
        "        content += f\"**Articles:** {paper['article_count']} | \"\n",
        "        content += f\"**Reading Time:** {paper['reading_time']} min\\n\"\n",
        "        if paper[\"topics\"]:\n",
        "            content += f\"**Topics:** {', '.join(paper['topics'])}\\n\"\n",
        "        if paper.get(\"tone\"):\n",
        "            content += f\"**Tone:** {paper['tone']}\\n\"\n",
        "\n",
        "        # Show structure if available\n",
        "        if paper.get(\"structure\"):\n",
        "            content += (\n",
        "                f\"**Structure:** {', '.join(paper['structure'].get('sections', []))}\\n\"\n",
        "            )\n",
        "\n",
        "        content += \"\\n---\\n\\n\"\n",
        "\n",
        "    return content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98aadae7",
      "metadata": {},
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "<img src=\"https://github.com/adityaarunsinghal/agentic-ai-workshop-2025/blob/main/notebooks/media/mcp_restaurant_09_notifications.png?raw=true\" width=\"500\" alt=\"mcp_restaurant_09_notifications\">\n",
        "<!-- <img src=\"https://github.com/adityaarunsinghal/agentic-ai-workshop-2025/blob/main/notebooks/media/mcp_restaurant_09_notifications.png?raw=true\" width=\"500\" alt=\"mcp_restaurant_09_notifications\"> -->\n",
        "\n",
        "### The servers let the clients know when something changes\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/adityaarunsinghal/agentic-ai-workshop-2025/blob/main/notebooks/media/mcp_restaurant_10_progress.png?raw=true\" width=\"500\" alt=\"mcp_restaurant_10_progress\">\n",
        "<!-- <img src=\"https://github.com/adityaarunsinghal/agentic-ai-workshop-2025/blob/main/notebooks/media/mcp_restaurant_10_progress.png?raw=true\" width=\"500\" alt=\"mcp_restaurant_10_progress\"> -->\n",
        "\n",
        "### They (kitchens) can also keep Ingrid and the waiters (MCP clients) in the know about where the dishes are in their prep!!\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "834352fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# TOOLS: CONTENT DISCOVERY\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "async def discover_stories(\n",
        "    query: str = \"tech news\",\n",
        "    count: int = 20,\n",
        "    sources: List[str] = None,\n",
        "    ctx: Context = None,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Discover stories from multiple sources and store with content IDs.\n",
        "\n",
        "    This is the PRIMARY discovery tool. It:\n",
        "    1. Fetches stories from sources (HN, web, etc.)\n",
        "    2. Stores full content in ChromaDB automatically\n",
        "    3. Generates clean content IDs for easy reference\n",
        "    4. Scores relevance against user interests\n",
        "    5. Finds related past coverage\n",
        "    6. Returns enriched summaries for decision-making\n",
        "\n",
        "    Args:\n",
        "        query: Search query (e.g., \"AI ethics\", \"distributed systems\")\n",
        "        count: Number of stories to fetch (1-30)\n",
        "        sources: List of sources [\"hn\", \"web\", \"perplexity\"] (default: [\"hn\"])\n",
        "\n",
        "    Returns:\n",
        "        Formatted list of stories with content IDs, titles, relevance scores,\n",
        "        and metadata. Use content IDs with other tools like quick_look() or\n",
        "        add_content_cluster().\n",
        "\n",
        "    Example:\n",
        "        discover_stories(\"AI ethics\", count=20, sources=[\"hn\", \"web\"])\n",
        "        â†’ Returns stories with IDs like cnt_hn_20251005_abc123\n",
        "    \"\"\"\n",
        "    if not 1 <= count <= 30:\n",
        "        return \"âŒ Count must be between 1 and 30\"\n",
        "\n",
        "    sources = sources or [\"hn\"]\n",
        "\n",
        "    hn_client = ctx.request_context.lifespan_context.hn_client\n",
        "    article_memory = ctx.request_context.lifespan_context.article_memory\n",
        "    interests_service = ctx.request_context.lifespan_context.interests_service\n",
        "\n",
        "    await ctx.info(f\"ðŸ” Discovering {count} stories from {sources}...\")\n",
        "\n",
        "    # Read user interests\n",
        "    interests = interests_service.read_interests()\n",
        "    user_topics = interests.get(\"topics\", [])\n",
        "\n",
        "    enriched_stories = []\n",
        "\n",
        "    # Fetch from Hacker News\n",
        "    if \"hn\" in sources:\n",
        "        await ctx.report_progress(progress=0, total=count)\n",
        "\n",
        "        story_ids = await hn_client.get_story_ids(\"topstories\", count)\n",
        "\n",
        "        for i, story_id in enumerate(story_ids):\n",
        "            story = await hn_client.get_item(story_id)\n",
        "            if not story or not story.get(\"title\"):\n",
        "                continue\n",
        "\n",
        "            await ctx.report_progress(progress=i + 1, total=count)\n",
        "\n",
        "            # Generate content ID\n",
        "            content_id = f\"cnt_hn_{datetime.now().strftime('%Y%m%d')}_{abs(hash(story['url'])) % 10000:04d}\"\n",
        "\n",
        "            # Fetch full content\n",
        "            try:\n",
        "                full_content = await fetch_content(story[\"url\"], max_length=8000)\n",
        "            except:\n",
        "                full_content = story.get(\"title\", \"\")\n",
        "\n",
        "            # Calculate relevance (simple keyword matching)\n",
        "            title_lower = story[\"title\"].lower()\n",
        "            relevance = sum(1 for topic in user_topics if topic.lower() in title_lower)\n",
        "            relevance_score = min(1.0, relevance / max(1, len(user_topics)))\n",
        "\n",
        "            # Extract matching topics\n",
        "            topics = [topic for topic in user_topics if topic.lower() in title_lower]\n",
        "\n",
        "            # Store in ChromaDB\n",
        "            await ctx.debug(f\"Storing content_id: {content_id}\")\n",
        "            article_memory.store_article_with_content_id(\n",
        "                content_id=content_id,\n",
        "                url=story[\"url\"],\n",
        "                content=full_content,\n",
        "                title=story[\"title\"],\n",
        "                source=\"hn\",\n",
        "                topics=topics,\n",
        "                summary=\"\",\n",
        "            )\n",
        "\n",
        "            # Search for related past articles\n",
        "            related = article_memory.search_articles(query=story[\"title\"], limit=3)\n",
        "\n",
        "            enriched_stories.append(\n",
        "                {\n",
        "                    \"content_id\": content_id,\n",
        "                    \"title\": story[\"title\"],\n",
        "                    \"url\": story[\"url\"],\n",
        "                    \"source\": \"hn\",\n",
        "                    \"score\": story.get(\"score\", 0),\n",
        "                    \"relevance_score\": relevance_score,\n",
        "                    \"word_count\": len(full_content.split()),\n",
        "                    \"estimated_reading_time\": max(1, len(full_content.split()) // 200),\n",
        "                    \"related_past_articles\": [a[\"title\"] for a in related],\n",
        "                    \"topics\": topics,\n",
        "                }\n",
        "            )\n",
        "\n",
        "    # Sort by relevance\n",
        "    enriched_stories.sort(key=lambda x: x[\"relevance_score\"], reverse=True)\n",
        "\n",
        "    # Format output\n",
        "    result = f\"# ðŸ“° Discovered {len(enriched_stories)} Stories\\n\\n\"\n",
        "    result += f\"**Query:** {query}\\n\"\n",
        "    result += f\"**Sources:** {', '.join(sources)}\\n\"\n",
        "    result += \"**Sorted by:** Relevance to your interests\\n\\n\"\n",
        "\n",
        "    for i, story in enumerate(enriched_stories, 1):\n",
        "        result += f\"## {i}. {story['title']}\\n\"\n",
        "        result += f\"**Content ID:** `{story['content_id']}`\\n\"\n",
        "        result += f\"**Relevance:** {story['relevance_score']:.0%} | \"\n",
        "        result += f\"**Reading Time:** {story['estimated_reading_time']}min | \"\n",
        "        result += f\"**HN Score:** {story['score']}\\n\"\n",
        "        if story[\"topics\"]:\n",
        "            result += f\"**Matching Interests:** {', '.join(story['topics'])}\\n\"\n",
        "        if story[\"related_past_articles\"]:\n",
        "            result += f\"**Related Past Coverage:** {len(story['related_past_articles'])} articles\\n\"\n",
        "        result += f\"**URL:** {story['url']}\\n\\n\"\n",
        "\n",
        "    await ctx.info(f\"âœ… Discovered and stored {len(enriched_stories)} stories\")\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "async def quick_look(content_ids: List[str], ctx: Context = None) -> str:\n",
        "    \"\"\"\n",
        "    Quick preview of stored content by content ID.\n",
        "\n",
        "    Use this to review content before adding to newspaper.\n",
        "    Shows title, metadata, and first 300 characters.\n",
        "\n",
        "    Args:\n",
        "        content_ids: List of content IDs to preview\n",
        "\n",
        "    Returns:\n",
        "        Compact preview of each content item\n",
        "\n",
        "    Example:\n",
        "        quick_look([\"cnt_hn_20251005_1234\", \"cnt_hn_20251005_5678\"])\n",
        "    \"\"\"\n",
        "    article_memory = ctx.request_context.lifespan_context.article_memory\n",
        "\n",
        "    previews = []\n",
        "    for content_id in content_ids:\n",
        "        article = article_memory.get_by_content_id(content_id)\n",
        "\n",
        "        if article:\n",
        "            previews.append(article)\n",
        "        else:\n",
        "            previews.append({\"content_id\": content_id, \"error\": \"Not found\"})\n",
        "\n",
        "    # Format output\n",
        "    result = f\"# ðŸ‘€ Quick Look: {len(content_ids)} items\\n\\n\"\n",
        "\n",
        "    for preview in previews:\n",
        "        if \"error\" in preview:\n",
        "            result += f\"## âŒ {preview['content_id']}\\n\"\n",
        "            result += f\"**Error:** {preview['error']}\\n\\n\"\n",
        "            continue\n",
        "\n",
        "        result += f\"## {preview['title']}\\n\"\n",
        "        result += f\"**Content ID:** `{preview['content_id']}`\\n\"\n",
        "        result += f\"**Word Count:** {preview['word_count']} | \"\n",
        "        result += f\"**Reading Time:** {preview.get('reading_time', '?')}min\\n\"\n",
        "        if preview.get(\"topics\"):\n",
        "            result += f\"**Topics:** {', '.join(preview['topics'])}\\n\"\n",
        "        result += f\"\\n**Preview:**\\n{preview['content_preview']}\\n\\n\"\n",
        "        result += \"---\\n\\n\"\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "06174ada",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# TOOLS: NEWSPAPER CREATION\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "async def create_newspaper(\n",
        "    title: str,\n",
        "    type: str = \"deep_dive\",\n",
        "    subtitle: str = \"\",\n",
        "    structure_template: str = None,\n",
        "    ctx: Context = None,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Create new newspaper with smart defaults.\n",
        "\n",
        "    Sets up newspaper structure based on type with pre-configured sections\n",
        "    and target reading times.\n",
        "\n",
        "    Args:\n",
        "        title: Newspaper title\n",
        "        type: Edition type - determines structure and targets\n",
        "              - \"morning_brief\": 2 sections, 15min target\n",
        "              - \"deep_dive\": 3-4 thematic sections, 35min target\n",
        "              - \"thematic\": Custom sections, agent-driven\n",
        "              - \"follow_up\": Timeline + Analysis, 20min target\n",
        "        subtitle: Optional subtitle\n",
        "        structure_template: Optional newspaper_id to copy structure from\n",
        "\n",
        "    Returns:\n",
        "        Newspaper ID and configuration details\n",
        "    \"\"\"\n",
        "    newspaper_service = ctx.request_context.lifespan_context.newspaper_service\n",
        "\n",
        "    # Type-specific defaults\n",
        "    type_configs = {\n",
        "        \"morning_brief\": {\n",
        "            \"sections\": [\"Breaking News\", \"Quick Reads\"],\n",
        "            \"target_reading_time\": 15,\n",
        "            \"suggested_articles\": 7,\n",
        "        },\n",
        "        \"deep_dive\": {\n",
        "            \"sections\": [\"Topic 1\", \"Topic 2\", \"Topic 3\"],\n",
        "            \"target_reading_time\": 35,\n",
        "            \"suggested_articles\": 10,\n",
        "        },\n",
        "        \"thematic\": {\n",
        "            \"sections\": [],  # Agent will define\n",
        "            \"target_reading_time\": 25,\n",
        "            \"suggested_articles\": 8,\n",
        "        },\n",
        "        \"follow_up\": {\n",
        "            \"sections\": [\"What Changed\", \"Deep Analysis\"],\n",
        "            \"target_reading_time\": 20,\n",
        "            \"suggested_articles\": 6,\n",
        "        },\n",
        "    }\n",
        "\n",
        "    config = type_configs.get(type, type_configs[\"deep_dive\"])\n",
        "\n",
        "    # Create newspaper\n",
        "    result = newspaper_service.create_draft(title, subtitle, type)\n",
        "\n",
        "    if not result[\"success\"]:\n",
        "        return f\"âŒ {result.get('error', 'Failed to create newspaper')}\"\n",
        "\n",
        "    newspaper_id = result[\"newspaper_id\"]\n",
        "\n",
        "    # Add pre-configured sections\n",
        "    for section_title in config[\"sections\"]:\n",
        "        newspaper_service.add_section(\n",
        "            newspaper_id,\n",
        "            section_title,\n",
        "            layout=\"featured\" if section_title == config[\"sections\"][0] else \"grid\",\n",
        "        )\n",
        "\n",
        "    # Set metadata\n",
        "    newspaper_service.set_metadata(\n",
        "        newspaper_id,\n",
        "        {\n",
        "            \"target_reading_time\": config[\"target_reading_time\"],\n",
        "            \"suggested_articles\": config[\"suggested_articles\"],\n",
        "        },\n",
        "    )\n",
        "\n",
        "    await ctx.info(f\"âœ… Created {type} newspaper: {newspaper_id}\")\n",
        "\n",
        "    response = \"# âœ… Created Newspaper\\n\\n\"\n",
        "    response += f\"**ID:** `{newspaper_id}`\\n\"\n",
        "    response += f\"**Title:** {title}\\n\"\n",
        "    response += f\"**Type:** {type}\\n\"\n",
        "    response += f\"**Target Reading Time:** {config['target_reading_time']} minutes\\n\"\n",
        "    response += f\"**Suggested Articles:** {config['suggested_articles']}\\n\\n\"\n",
        "\n",
        "    if config[\"sections\"]:\n",
        "        response += \"**Pre-configured Sections:**\\n\"\n",
        "        for section in config[\"sections\"]:\n",
        "            response += f\"- {section}\\n\"\n",
        "\n",
        "    response += \"\\n**Next Steps:**\\n\"\n",
        "    response += \"1. Use add_content_cluster() to add articles\\n\"\n",
        "    response += \"2. Polish with section/article controls\\n\"\n",
        "    response += \"3. validate_and_finalize() to check quality\\n\"\n",
        "    response += \"4. publish_newspaper() to deliver\\n\"\n",
        "\n",
        "    return response\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "async def add_content_cluster(\n",
        "    newspaper_id: str,\n",
        "    section: str,\n",
        "    content_ids: List[str],\n",
        "    treatment: str = \"detailed\",\n",
        "    auto_enhance: bool = True,\n",
        "    link_related: bool = True,\n",
        "    ctx: Context = None,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Add multiple related articles as a coherent cluster - THE WORKHORSE TOOL.\n",
        "\n",
        "    This tool does EVERYTHING in one call:\n",
        "    - Fetches content from ChromaDB (already stored by discover_stories)\n",
        "    - Reads interests automatically\n",
        "    - Finds related past coverage\n",
        "    - Uses sampling to generate summaries with full context\n",
        "    - Formats with rich elements (quotes, key points)\n",
        "    - Links related articles\n",
        "    - Updates newspaper\n",
        "\n",
        "    If content_ids > 5, may elicit user preference on depth.\n",
        "\n",
        "    Args:\n",
        "        newspaper_id: Target newspaper\n",
        "        section: Section to add to\n",
        "        content_ids: List of content IDs to add\n",
        "        treatment: Summary style\n",
        "                   - \"brief\": Quick overview (2-3 sentences)\n",
        "                   - \"detailed\": Comprehensive summary (6-8 sentences)\n",
        "                   - \"technical\": Focus on technical details\n",
        "        auto_enhance: Automatically add pull quotes and key points\n",
        "        link_related: Cross-reference articles in cluster\n",
        "\n",
        "    Returns:\n",
        "        Summary of articles added and enhancements applied\n",
        "    \"\"\"\n",
        "    if len(content_ids) == 0:\n",
        "        return \"âŒ No content IDs provided\"\n",
        "\n",
        "    article_memory = ctx.request_context.lifespan_context.article_memory\n",
        "    newspaper_service = ctx.request_context.lifespan_context.newspaper_service\n",
        "    interests_service = ctx.request_context.lifespan_context.interests_service\n",
        "\n",
        "    await ctx.info(f\"ðŸ“ Adding {len(content_ids)} articles to '{section}'...\")\n",
        "\n",
        "    # Elicit if too many articles\n",
        "    if len(content_ids) > 5:\n",
        "        from dataclasses import make_dataclass\n",
        "\n",
        "        choice_response = await ctx.elicit(\n",
        "            message=f\"Found {len(content_ids)} articles. Include all (comprehensive) or top 5 (focused)?\",\n",
        "            response_type=make_dataclass(\"SelectionChoice\", [(\"selection\", str)]),\n",
        "        )\n",
        "\n",
        "        if (\n",
        "            choice_response.action == \"accept\"\n",
        "            and choice_response.data.selection == \"focused\"\n",
        "        ):\n",
        "            content_ids = content_ids[:5]\n",
        "            await ctx.info(\"ðŸ“Š User selected focused approach - using top 5 articles\")\n",
        "\n",
        "    # Read interests\n",
        "    interests = interests_service.read_interests()\n",
        "\n",
        "    # Fetch all articles from ChromaDB\n",
        "    articles = []\n",
        "    for content_id in content_ids:\n",
        "        article = article_memory.get_by_content_id(content_id)\n",
        "        if article:\n",
        "            articles.append(article)\n",
        "        else:\n",
        "            await ctx.warning(f\"Content ID not found: {content_id}\")\n",
        "\n",
        "    if not articles:\n",
        "        return \"âŒ No valid articles found\"\n",
        "\n",
        "    await ctx.report_progress(progress=0, total=len(articles))\n",
        "\n",
        "    # Process each article\n",
        "    added_articles = []\n",
        "    total_reading_time = 0\n",
        "\n",
        "    for i, article in enumerate(articles):\n",
        "        await ctx.debug(f\"Processing: {article['title']}\")\n",
        "\n",
        "        # Find related past coverage\n",
        "        related = article_memory.search_articles(query=article[\"content\"], limit=5)\n",
        "\n",
        "        # Use sampling to generate summary\n",
        "        await ctx.info(f\"ðŸ¤– Generating {treatment} summary with LLM...\")\n",
        "\n",
        "        sample_result = await ctx.sample(\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": f\"\"\"Summarize this article in {treatment} style.\n",
        "\n",
        "USER INTERESTS:\n",
        "{chr(10).join(f\"- {topic}\" for topic in interests.get(\"topics\", []))}\n",
        "\n",
        "PAST COVERAGE (for context):\n",
        "{chr(10).join(f\"- {r['title']}\" for r in related[:3])}\n",
        "\n",
        "ARTICLE TO SUMMARIZE:\n",
        "Title: {article[\"title\"]}\n",
        "Content: {article[\"content\"]}\n",
        "\n",
        "Provide a {treatment} summary that connects to user interests and acknowledges past coverage when relevant.\"\"\",\n",
        "                    },\n",
        "                }\n",
        "            ],\n",
        "            temperature=0.3,\n",
        "            max_tokens=500 if treatment == \"brief\" else 1000,\n",
        "        )\n",
        "\n",
        "        # Direct access to text from sampling result\n",
        "        summary = sample_result.text\n",
        "\n",
        "        # Auto-enhance if requested\n",
        "        pull_quote = \"\"\n",
        "        key_points = []\n",
        "\n",
        "        if auto_enhance:\n",
        "            await ctx.info(\"âœ¨ Extracting pull quote and key points...\")\n",
        "\n",
        "            # Extract pull quote\n",
        "            quote_result = await ctx.sample(\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": {\n",
        "                            \"type\": \"text\",\n",
        "                            \"text\": f\"Extract the single most impactful quote from this article (15-30 words):\\n\\n{article['content'][:2000]}\",\n",
        "                        },\n",
        "                    }\n",
        "                ],\n",
        "                temperature=0.2,\n",
        "                max_tokens=100,\n",
        "            )\n",
        "            # Direct access to text from sampling result\n",
        "            pull_quote = quote_result.text\n",
        "\n",
        "            # Extract key points\n",
        "            points_result = await ctx.sample(\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": {\n",
        "                            \"type\": \"text\",\n",
        "                            \"text\": f\"Extract 3-5 key points from this article as a bullet list:\\n\\n{article['content'][:2000]}\",\n",
        "                        },\n",
        "                    }\n",
        "                ],\n",
        "                temperature=0.2,\n",
        "                max_tokens=300,\n",
        "            )\n",
        "            # Direct access to text from sampling result\n",
        "            points_text = points_result.text\n",
        "            key_points = [\n",
        "                line.strip(\"- \").strip()\n",
        "                for line in points_text.split(\"\\n\")\n",
        "                if line.strip().startswith(\"-\")\n",
        "            ]\n",
        "\n",
        "        # Add to newspaper\n",
        "        newspaper_service.add_article(\n",
        "            newspaper_id=newspaper_id,\n",
        "            section_title=section,\n",
        "            article_data={\n",
        "                \"title\": article[\"title\"],\n",
        "                \"content\": summary,\n",
        "                \"url\": article[\"url\"],\n",
        "                \"source\": article[\"source\"],\n",
        "                \"tags\": article.get(\"topics\", []),\n",
        "            },\n",
        "            placement=\"lead\" if i == 0 else \"standard\",\n",
        "        )\n",
        "\n",
        "        # Apply formatting\n",
        "        newspaper_service.set_article_format(\n",
        "            newspaper_id=newspaper_id,\n",
        "            section_title=section,\n",
        "            article_title=article[\"title\"],\n",
        "            format_options={\"pull_quote\": pull_quote, \"key_points\": key_points},\n",
        "        )\n",
        "\n",
        "        added_articles.append(article[\"title\"])\n",
        "        total_reading_time += article.get(\"reading_time\", 1)\n",
        "\n",
        "        await ctx.report_progress(progress=i + 1, total=len(articles))\n",
        "\n",
        "    # Link related if requested\n",
        "    if link_related and len(added_articles) > 1:\n",
        "        for i, title in enumerate(added_articles):\n",
        "            related_titles = [t for j, t in enumerate(added_articles) if j != i]\n",
        "            newspaper_service.link_related_articles(\n",
        "                newspaper_id=newspaper_id,\n",
        "                article_title=title,\n",
        "                related_titles=related_titles[:3],  # Max 3 links\n",
        "            )\n",
        "\n",
        "    await ctx.info(f\"âœ… Added {len(added_articles)} articles to '{section}'\")\n",
        "\n",
        "    result = \"# âœ… Content Cluster Added\\n\\n\"\n",
        "    result += f\"**Section:** {section}\\n\"\n",
        "    result += f\"**Articles Added:** {len(added_articles)}\\n\"\n",
        "    result += f\"**Reading Time Added:** ~{total_reading_time} minutes\\n\"\n",
        "    result += f\"**Treatment:** {treatment}\\n\\n\"\n",
        "\n",
        "    result += \"**Articles:**\\n\"\n",
        "    for title in added_articles:\n",
        "        result += f\"- {title}\\n\"\n",
        "\n",
        "    if auto_enhance:\n",
        "        result += \"\\n**Enhancements Applied:**\\n\"\n",
        "        result += \"- Pull quotes extracted\\n\"\n",
        "        result += \"- Key points identified\\n\"\n",
        "\n",
        "    if link_related:\n",
        "        result += \"- Related articles cross-referenced\\n\"\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "async def create_editorial_synthesis(\n",
        "    newspaper_id: str,\n",
        "    content_ids: List[str],\n",
        "    angle: str = \"analytical\",\n",
        "    placement: str = \"section_intro\",\n",
        "    ctx: Context = None,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Generate editorial content connecting multiple stories using sampling.\n",
        "\n",
        "    Uses LLM to synthesize insights across articles with full context from\n",
        "    interests and past coverage.\n",
        "\n",
        "    Args:\n",
        "        newspaper_id: Target newspaper\n",
        "        content_ids: Stories to synthesize\n",
        "        angle: Editorial perspective\n",
        "               - \"analytical\": Objective analysis with implications\n",
        "               - \"educational\": Explain concepts with context\n",
        "               - \"skeptical\": Question assumptions, highlight concerns\n",
        "               - \"forward-looking\": Future trends and predictions\n",
        "        placement: Where to place\n",
        "                   - \"section_intro\": Introduction to section\n",
        "                   - \"theme_bridge\": Connect different topics\n",
        "                   - \"closing_thoughts\": Wrap-up perspective\n",
        "\n",
        "    Returns:\n",
        "        Confirmation of editorial added\n",
        "    \"\"\"\n",
        "    article_memory = ctx.request_context.lifespan_context.article_memory\n",
        "    newspaper_service = ctx.request_context.lifespan_context.newspaper_service\n",
        "    interests_service = ctx.request_context.lifespan_context.interests_service\n",
        "\n",
        "    await ctx.info(f\"âœï¸ Generating {angle} editorial...\")\n",
        "\n",
        "    # Fetch articles\n",
        "    articles = []\n",
        "    for content_id in content_ids:\n",
        "        article = article_memory.get_by_content_id(content_id)\n",
        "        if article:\n",
        "            articles.append(article)\n",
        "\n",
        "    if not articles:\n",
        "        return \"âŒ No valid articles found\"\n",
        "\n",
        "    # Read interests\n",
        "    interests = interests_service.read_interests()\n",
        "\n",
        "    # Prepare context\n",
        "    articles_summary = \"\\n\\n\".join(\n",
        "        [f\"Article: {a['title']}\\nContent: {a['content'][:500]}...\" for a in articles]\n",
        "    )\n",
        "\n",
        "    # Generate editorial\n",
        "    await ctx.info(\"ðŸ¤– Generating editorial with LLM...\")\n",
        "\n",
        "    angle_instructions = {\n",
        "        \"analytical\": \"Provide objective analysis with insights and implications\",\n",
        "        \"educational\": \"Explain concepts clearly with context for learning\",\n",
        "        \"skeptical\": \"Question assumptions and highlight potential concerns\",\n",
        "        \"forward-looking\": \"Identify future trends and make predictions\",\n",
        "    }\n",
        "\n",
        "    sample_result = await ctx.sample(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": f\"\"\"Write a {angle} editorial connecting these stories (300-400 words).\n",
        "\n",
        "{angle_instructions[angle]}\n",
        "\n",
        "USER INTERESTS:\n",
        "{chr(10).join(f\"- {topic}\" for topic in interests.get(\"topics\", []))}\n",
        "\n",
        "STORIES TO CONNECT:\n",
        "{articles_summary}\n",
        "\n",
        "Write an editorial that synthesizes these stories into a coherent narrative.\"\"\",\n",
        "                },\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "        max_tokens=600,\n",
        "    )\n",
        "\n",
        "    # Direct access to text from sampling result\n",
        "    editorial = sample_result.text\n",
        "\n",
        "    # Add to newspaper\n",
        "    newspaper_service.add_editors_note(\n",
        "        newspaper_id=newspaper_id,\n",
        "        content=editorial,\n",
        "        placement=placement,\n",
        "        style=\"highlighted\",\n",
        "    )\n",
        "\n",
        "    await ctx.info(f\"âœ… Editorial added with {angle} perspective\")\n",
        "\n",
        "    return f\"âœ… Editorial synthesis added\\n\\n**Angle:** {angle}\\n**Placement:** {placement}\\n**Stories Connected:** {len(articles)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "877c1ecf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# TOOLS: POLISH & EDITORIAL CONTROL\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "async def set_section_style(\n",
        "    newspaper_id: str, section: str, layout: str = \"grid\", ctx: Context = None\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Control section visual presentation.\n",
        "\n",
        "    Args:\n",
        "        newspaper_id: Target newspaper\n",
        "        section: Section to style\n",
        "        layout: Layout type\n",
        "                - \"featured\": One big article, rest smaller\n",
        "                - \"grid\": Equal-sized grid layout\n",
        "                - \"timeline\": Timeline with chronological flow\n",
        "                - \"single-column\": Single column for long-form\n",
        "    \"\"\"\n",
        "    newspaper_service = ctx.request_context.lifespan_context.newspaper_service\n",
        "\n",
        "    result = newspaper_service.set_section_layout(newspaper_id, section, layout)\n",
        "\n",
        "    if result[\"success\"]:\n",
        "        return f\"âœ… Set '{section}' to {layout} layout\"\n",
        "    else:\n",
        "        return f\"âŒ {result['error']}\"\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "async def enhance_article(\n",
        "    newspaper_id: str,\n",
        "    section: str,\n",
        "    article_title: str,\n",
        "    add_pull_quote: bool = False,\n",
        "    add_key_points: bool = False,\n",
        "    ctx: Context = None,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Add polish to specific article using LLM extraction.\n",
        "\n",
        "    Args:\n",
        "        newspaper_id: Target newspaper\n",
        "        section: Section containing article\n",
        "        article_title: Article to enhance\n",
        "        add_pull_quote: Extract compelling quote\n",
        "        add_key_points: Extract key takeaways\n",
        "    \"\"\"\n",
        "    newspaper_service = ctx.request_context.lifespan_context.newspaper_service\n",
        "    article_memory = ctx.request_context.lifespan_context.article_memory\n",
        "\n",
        "    # Get article content\n",
        "    newspaper_data = newspaper_service.get_newspaper_data(newspaper_id)\n",
        "    if not newspaper_data:\n",
        "        return \"âŒ Newspaper not found\"\n",
        "\n",
        "    # Find article\n",
        "    article = None\n",
        "    for s in newspaper_data[\"sections\"]:\n",
        "        if s[\"title\"] == section:\n",
        "            for a in s[\"articles\"]:\n",
        "                if a[\"title\"] == article_title:\n",
        "                    article = a\n",
        "                    break\n",
        "\n",
        "    if not article:\n",
        "        return \"âŒ Article not found\"\n",
        "\n",
        "    enhancements = {}\n",
        "\n",
        "    # Extract pull quote if requested\n",
        "    if add_pull_quote:\n",
        "        await ctx.info(\"âœ¨ Extracting pull quote...\")\n",
        "        quote_result = await ctx.sample(\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": f\"Extract the most compelling quote from this article (15-30 words):\\n\\n{article['content']}\",\n",
        "                    },\n",
        "                }\n",
        "            ],\n",
        "            temperature=0.2,\n",
        "            max_tokens=100,\n",
        "        )\n",
        "        enhancements[\"pull_quote\"] = quote_result.text\n",
        "\n",
        "    # Extract key points if requested\n",
        "    if add_key_points:\n",
        "        await ctx.info(\"âœ¨ Extracting key points...\")\n",
        "        points_result = await ctx.sample(\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": f\"Extract 3-5 key points from this article as a bullet list:\\n\\n{article['content']}\",\n",
        "                    },\n",
        "                }\n",
        "            ],\n",
        "            temperature=0.2,\n",
        "            max_tokens=300,\n",
        "        )\n",
        "        points_text = points_result.text\n",
        "        enhancements[\"key_points\"] = [\n",
        "            line.strip(\"- \").strip()\n",
        "            for line in points_text.split(\"\\n\")\n",
        "            if line.strip().startswith(\"-\")\n",
        "        ]\n",
        "\n",
        "    # Apply enhancements\n",
        "    newspaper_service.set_article_format(\n",
        "        newspaper_id=newspaper_id,\n",
        "        section_title=section,\n",
        "        article_title=article_title,\n",
        "        format_options=enhancements,\n",
        "    )\n",
        "\n",
        "    return f\"âœ… Enhanced '{article_title}' with {len(enhancements)} enhancements\"\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "async def reorder_and_emphasize(\n",
        "    newspaper_id: str,\n",
        "    section: str,\n",
        "    article_order: List[str],\n",
        "    highlights: Dict[str, str] = None,\n",
        "    ctx: Context = None,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Control narrative flow and emphasis within section.\n",
        "\n",
        "    Args:\n",
        "        newspaper_id: Target newspaper\n",
        "        section: Section to reorder\n",
        "        article_order: List of article titles in desired order\n",
        "        highlights: Dict mapping article title to highlight type\n",
        "                    - \"breaking\": Breaking news badge\n",
        "                    - \"exclusive\": Exclusive content badge\n",
        "                    - \"trending\": Trending badge\n",
        "                    - \"deep-dive\": Deep dive badge\n",
        "    \"\"\"\n",
        "    newspaper_service = ctx.request_context.lifespan_context.newspaper_service\n",
        "\n",
        "    # Get section\n",
        "    newspaper_data = newspaper_service.get_newspaper_data(newspaper_id)\n",
        "    if not newspaper_data:\n",
        "        return \"âŒ Newspaper not found\"\n",
        "\n",
        "    section_data = None\n",
        "    for s in newspaper_data[\"sections\"]:\n",
        "        if s[\"title\"] == section:\n",
        "            section_data = s\n",
        "            break\n",
        "\n",
        "    if not section_data:\n",
        "        return f\"âŒ Section '{section}' not found\"\n",
        "\n",
        "    # Reorder articles\n",
        "    current_articles = {a[\"title\"]: a for a in section_data[\"articles\"]}\n",
        "    reordered = []\n",
        "\n",
        "    for title in article_order:\n",
        "        if title in current_articles:\n",
        "            reordered.append(current_articles[title])\n",
        "        else:\n",
        "            return f\"âŒ Article '{title}' not found in section\"\n",
        "\n",
        "    section_data[\"articles\"] = reordered\n",
        "\n",
        "    # Apply highlights\n",
        "    highlights = highlights or {}\n",
        "    for article_title, highlight_type in highlights.items():\n",
        "        newspaper_service.highlight_article(\n",
        "            newspaper_id=newspaper_id,\n",
        "            section_title=section,\n",
        "            article_title=article_title,\n",
        "            highlight_type=highlight_type,\n",
        "        )\n",
        "\n",
        "    # Save changes\n",
        "    newspaper_service._save_draft(newspaper_id, newspaper_data)\n",
        "\n",
        "    return f\"âœ… Reordered {len(article_order)} articles in '{section}' with {len(highlights)} highlights\"\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "async def add_editorial_element(\n",
        "    newspaper_id: str,\n",
        "    element_type: str,\n",
        "    placement: str = \"top\",\n",
        "    content: str = \"\",\n",
        "    generate: bool = False,\n",
        "    generation_context: str = \"\",\n",
        "    ctx: Context = None,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Add editorial elements (notes, highlights, etc).\n",
        "\n",
        "    Can either use provided content OR generate using LLM.\n",
        "\n",
        "    Args:\n",
        "        newspaper_id: Target newspaper\n",
        "        element_type: Type of element\n",
        "                      - \"editors_note\": Editor's commentary\n",
        "                      - \"theme_highlight\": Connect cross-theme stories\n",
        "                      - \"stats_callout\": Highlight key statistics\n",
        "        placement: Where to place (\"top\", \"bottom\", or \"section:<name>\")\n",
        "        content: Content to use (if not generating)\n",
        "        generate: If True, use LLM to generate content\n",
        "        generation_context: Context for generation (e.g., \"Connect privacy and performance themes\")\n",
        "    \"\"\"\n",
        "    newspaper_service = ctx.request_context.lifespan_context.newspaper_service\n",
        "\n",
        "    # Generate content if requested\n",
        "    if generate and generation_context:\n",
        "        await ctx.info(f\"ðŸ¤– Generating {element_type} content...\")\n",
        "\n",
        "        newspaper_data = newspaper_service.get_newspaper_data(newspaper_id)\n",
        "\n",
        "        sample_result = await ctx.sample(\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": f\"\"\"Generate a {element_type} for a newspaper.\n",
        "\n",
        "Context: {generation_context}\n",
        "\n",
        "Newspaper Title: {newspaper_data.get(\"title\", \"\")}\n",
        "Sections: {\", \".join(s[\"title\"] for s in newspaper_data.get(\"sections\", []))}\n",
        "\n",
        "Write 2-3 sentences appropriate for a {element_type}.\"\"\",\n",
        "                    },\n",
        "                }\n",
        "            ],\n",
        "            temperature=0.6,\n",
        "            max_tokens=200,\n",
        "        )\n",
        "\n",
        "        # Direct access to text from sampling result\n",
        "        content = sample_result.text\n",
        "\n",
        "    # Add element based on type\n",
        "    if element_type == \"editors_note\":\n",
        "        newspaper_service.add_editors_note(\n",
        "            newspaper_id=newspaper_id,\n",
        "            content=content,\n",
        "            placement=placement,\n",
        "            style=\"highlighted\",\n",
        "        )\n",
        "    elif element_type == \"theme_highlight\":\n",
        "        newspaper_service.add_theme_highlight(\n",
        "            newspaper_id=newspaper_id,\n",
        "            theme=generation_context.split()[0] if generation_context else \"Theme\",\n",
        "            description=content,\n",
        "            related_articles=[],\n",
        "        )\n",
        "    else:\n",
        "        return f\"âŒ Unsupported element type: {element_type}\"\n",
        "\n",
        "    return f\"âœ… Added {element_type} at {placement}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4d9af0da",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# TOOLS: QUALITY CONTROL & DELIVERY\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "async def preview_newspaper(\n",
        "    newspaper_id: str, preview_type: str = \"summary\", ctx: Context = None\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Preview newspaper with different analysis views.\n",
        "\n",
        "    Args:\n",
        "        newspaper_id: Newspaper to preview\n",
        "        preview_type: Type of preview\n",
        "                      - \"summary\": Stats and metadata\n",
        "                      - \"structure\": Section breakdown\n",
        "                      - \"full\": Complete markdown\n",
        "    \"\"\"\n",
        "    newspaper_service = ctx.request_context.lifespan_context.newspaper_service\n",
        "\n",
        "    if preview_type in [\"summary\", \"structure\"]:\n",
        "        result = newspaper_service.get_stats(newspaper_id)\n",
        "        if not result[\"success\"]:\n",
        "            return f\"âŒ {result['error']}\"\n",
        "\n",
        "        stats = result[\"stats\"]\n",
        "        output = \"# ðŸ“Š Newspaper Summary\\n\\n\"\n",
        "        output += f\"**Title:** {stats['title']}\\n\"\n",
        "        output += f\"**Type:** {stats['edition_type']}\\n\"\n",
        "        output += f\"**Articles:** {stats['total_articles']}\\n\"\n",
        "        output += f\"**Reading Time:** {stats['total_reading_time']} minutes\\n\"\n",
        "        output += f\"**Sections:** {stats['section_count']}\\n\\n\"\n",
        "\n",
        "        output += \"**Section Breakdown:**\\n\"\n",
        "        for section in stats[\"sections\"]:\n",
        "            output += f\"- {section['title']} ({section['layout']}): {section['article_count']} articles\\n\"\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "async def validate_and_finalize(\n",
        "    newspaper_id: str,\n",
        "    min_reading_time: int = None,\n",
        "    min_articles: int = None,\n",
        "    ctx: Context = None,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Validate newspaper meets quality standards with ENFORCEMENT.\n",
        "\n",
        "    Unlike old design, this PREVENTS publication if standards not met\n",
        "    and provides actionable fixes.\n",
        "\n",
        "    Args:\n",
        "        newspaper_id: Newspaper to validate\n",
        "        min_reading_time: Minimum reading time in minutes (optional)\n",
        "        min_articles: Minimum number of articles (optional)\n",
        "\n",
        "    Returns:\n",
        "        Validation results with actionable fixes if needed\n",
        "    \"\"\"\n",
        "    newspaper_service = ctx.request_context.lifespan_context.newspaper_service\n",
        "\n",
        "    await ctx.info(\"ðŸ” Validating newspaper quality...\")\n",
        "\n",
        "    # Get newspaper data\n",
        "    newspaper_data = newspaper_service.get_newspaper_data(newspaper_id)\n",
        "    if not newspaper_data:\n",
        "        return \"âŒ Newspaper not found\"\n",
        "\n",
        "    # Check basic validation\n",
        "    result = newspaper_service.validate(newspaper_id)\n",
        "\n",
        "    issues = []\n",
        "    warnings = []\n",
        "\n",
        "    # Check custom requirements\n",
        "    current_reading_time = newspaper_data[\"metadata\"][\"total_reading_time\"]\n",
        "    current_articles = newspaper_data[\"metadata\"][\"article_count\"]\n",
        "\n",
        "    if min_reading_time and current_reading_time < min_reading_time:\n",
        "        shortfall = min_reading_time - current_reading_time\n",
        "        issues.append(\n",
        "            {\n",
        "                \"type\": \"reading_time\",\n",
        "                \"current\": current_reading_time,\n",
        "                \"required\": min_reading_time,\n",
        "                \"suggestion\": f\"Add {shortfall // 3} more detailed articles (~3min each)\",\n",
        "                \"fix\": f\"Use add_content_cluster() with {shortfall // 3} content IDs and treatment='detailed'\",\n",
        "            }\n",
        "        )\n",
        "\n",
        "    if min_articles and current_articles < min_articles:\n",
        "        shortfall = min_articles - current_articles\n",
        "        issues.append(\n",
        "            {\n",
        "                \"type\": \"article_count\",\n",
        "                \"current\": current_articles,\n",
        "                \"required\": min_articles,\n",
        "                \"suggestion\": f\"Add {shortfall} more articles\",\n",
        "                \"fix\": f\"Use add_content_cluster() with {shortfall} content IDs\",\n",
        "            }\n",
        "        )\n",
        "\n",
        "    # Check for empty sections\n",
        "    for section in newspaper_data[\"sections\"]:\n",
        "        if not section[\"articles\"]:\n",
        "            warnings.append(f\"Section '{section['title']}' is empty\")\n",
        "\n",
        "    # Combine with basic validation\n",
        "    all_issues = result.get(\"issues\", []) + [i[\"type\"] for i in issues]\n",
        "    all_warnings = result.get(\"warnings\", []) + warnings\n",
        "\n",
        "    # Format output\n",
        "    if not all_issues:\n",
        "        output = \"# âœ… Newspaper Valid!\\n\\n\"\n",
        "        output += \"All quality standards met. Ready to publish.\\n\\n\"\n",
        "\n",
        "        if all_warnings:\n",
        "            output += \"**Warnings:**\\n\"\n",
        "            for warning in all_warnings:\n",
        "                output += f\"âš ï¸ {warning}\\n\"\n",
        "\n",
        "        return output\n",
        "    else:\n",
        "        output = \"# âŒ Newspaper Needs Improvement\\n\\n\"\n",
        "\n",
        "        output += \"**Issues Found:**\\n\"\n",
        "        for issue in issues:\n",
        "            output += f\"\\n**{issue['type'].replace('_', ' ').title()}**\\n\"\n",
        "            output += f\"- Current: {issue['current']}\\n\"\n",
        "            output += f\"- Required: {issue['required']}\\n\"\n",
        "            output += f\"- Suggestion: {issue['suggestion']}\\n\"\n",
        "            output += f\"- Fix: `{issue['fix']}`\\n\"\n",
        "\n",
        "        if all_warnings:\n",
        "            output += \"\\n**Warnings:**\\n\"\n",
        "            for warning in all_warnings:\n",
        "                output += f\"âš ï¸ {warning}\\n\"\n",
        "\n",
        "        output += \"\\n**Cannot publish until issues resolved.**\\n\"\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "async def publish_newspaper(\n",
        "    newspaper_id: str, delivery_method: str = \"email\", ctx: Context = None\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Finalize and deliver newspaper.\n",
        "\n",
        "    Args:\n",
        "        newspaper_id: Newspaper to publish\n",
        "        delivery_method: How to deliver\n",
        "                         - \"email\": Send via email\n",
        "                         - \"save_html\": Save HTML locally\n",
        "                         - \"both\": Email and save\n",
        "    \"\"\"\n",
        "    newspaper_service = ctx.request_context.lifespan_context.newspaper_service\n",
        "    email_service = ctx.request_context.lifespan_context.email_service\n",
        "    article_memory = ctx.request_context.lifespan_context.article_memory\n",
        "    settings = ctx.request_context.lifespan_context.settings\n",
        "\n",
        "    await ctx.info(\"ðŸ“° Publishing newspaper...\")\n",
        "\n",
        "    # Get newspaper data\n",
        "    newspaper_data = newspaper_service.get_newspaper_data(newspaper_id)\n",
        "    if not newspaper_data:\n",
        "        return \"âŒ Newspaper not found\"\n",
        "\n",
        "    # Generate HTML\n",
        "    await ctx.report_progress(progress=0, total=3)\n",
        "    html_content = email_service._create_html_version(newspaper_data)\n",
        "\n",
        "    # Save HTML\n",
        "    html_file = settings.data_dir / \"newspapers\" / f\"{newspaper_id}.html\"\n",
        "    html_file.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(html_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(html_content)\n",
        "\n",
        "    await ctx.report_progress(progress=1, total=3)\n",
        "\n",
        "    # Send email if requested\n",
        "    email_sent = False\n",
        "    if delivery_method in [\"email\", \"both\"]:\n",
        "        result = email_service.send_newspaper(newspaper_data, version=2)\n",
        "        email_sent = result[\"success\"]\n",
        "        if not email_sent:\n",
        "            await ctx.warning(f\"Email failed: {result.get('error', 'Unknown error')}\")\n",
        "\n",
        "    await ctx.report_progress(progress=2, total=3)\n",
        "\n",
        "    # Store in archive\n",
        "    article_memory.store_newspaper(newspaper_id, newspaper_data)\n",
        "\n",
        "    await ctx.report_progress(progress=3, total=3)\n",
        "    await ctx.info(\"âœ… Newspaper published and archived\")\n",
        "\n",
        "    # Format output\n",
        "    output = \"# âœ… Newspaper Published!\\n\\n\"\n",
        "    output += f\"**Title:** {newspaper_data['title']}\\n\"\n",
        "    output += f\"**Articles:** {newspaper_data['metadata']['article_count']}\\n\"\n",
        "    output += f\"**Reading Time:** {newspaper_data['metadata']['total_reading_time']} minutes\\n\\n\"\n",
        "\n",
        "    if email_sent:\n",
        "        output += \"ðŸ“§ **Email:** Sent successfully\\n\"\n",
        "\n",
        "    if delivery_method in [\"save_html\", \"both\"] or not email_sent:\n",
        "        output += f\"ðŸ’¾ **HTML:** Saved to {html_file}\\n\"\n",
        "\n",
        "    output += \"ðŸ—„ï¸ **Archive:** Stored in memory\\n\"\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8dd29a56",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# TOOLS: CONTEXT HELPERS\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "async def search_context(\n",
        "    query: str, context_type: str = \"articles\", limit: int = 10, ctx: Context = None\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Search archive for relevant context.\n",
        "\n",
        "    Args:\n",
        "        query: Search query\n",
        "        context_type: What to search\n",
        "                      - \"articles\": Search article archive\n",
        "                      - \"newspapers\": Search past newspapers\n",
        "                      - \"topics\": Search by topic\n",
        "        limit: Maximum results (1-20)\n",
        "    \"\"\"\n",
        "    article_memory = ctx.request_context.lifespan_context.article_memory\n",
        "\n",
        "    if context_type == \"articles\":\n",
        "        articles = article_memory.search_articles(query=query, limit=limit)\n",
        "\n",
        "        if not articles:\n",
        "            return f\"No articles found for '{query}'\"\n",
        "\n",
        "        result = f\"# ðŸ” Found {len(articles)} Articles\\n\\n\"\n",
        "        for i, article in enumerate(articles, 1):\n",
        "            result += f\"## {i}. {article['title']}\\n\"\n",
        "            result += f\"**Content ID:** {article.get('content_id', 'unknown')}\\n\"\n",
        "            result += f\"**Similarity:** {article['similarity']:.1%}\\n\"\n",
        "            result += f\"**Source:** {article['source']}\\n\\n\"\n",
        "\n",
        "        return result\n",
        "\n",
        "    elif context_type == \"newspapers\":\n",
        "        newspapers = article_memory.search_newspapers(days_back=90, query=query)\n",
        "\n",
        "        if not newspapers:\n",
        "            return f\"No newspapers found for '{query}'\"\n",
        "\n",
        "        result = f\"# ðŸ” Found {len(newspapers)} Newspapers\\n\\n\"\n",
        "        for paper in newspapers:\n",
        "            result += f\"## {paper['title']}\\n\"\n",
        "            result += f\"**Date:** {paper['timestamp'][:10]}\\n\"\n",
        "            result += f\"**Type:** {paper['edition_type']}\\n\"\n",
        "            result += f\"**Articles:** {paper['article_count']}\\n\\n\"\n",
        "\n",
        "        return result\n",
        "\n",
        "    else:\n",
        "        return f\"âŒ Unsupported context type: {context_type}\"\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "async def get_related_content(\n",
        "    content_id: str,\n",
        "    relationship_type: str = \"similar\",\n",
        "    limit: int = 5,\n",
        "    ctx: Context = None,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Find content related to a specific article.\n",
        "\n",
        "    Args:\n",
        "        content_id: Content ID to find relations for\n",
        "        relationship_type: Type of relationship\n",
        "                           - \"similar\": Similar content\n",
        "                           - \"follow_up\": Follow-up coverage\n",
        "                           - \"background\": Background context\n",
        "        limit: Maximum results (1-20)\n",
        "    \"\"\"\n",
        "    article_memory = ctx.request_context.lifespan_context.article_memory\n",
        "\n",
        "    # Get base article\n",
        "    article = article_memory.get_by_content_id(content_id)\n",
        "    if not article:\n",
        "        return f\"âŒ Content ID not found: {content_id}\"\n",
        "\n",
        "    # Search for related\n",
        "    related = article_memory.search_articles(query=article[\"content\"], limit=limit)\n",
        "\n",
        "    # Filter out the original article\n",
        "    related = [r for r in related if r.get(\"content_id\") != content_id]\n",
        "\n",
        "    if not related:\n",
        "        return f\"No related content found for '{article['title']}'\"\n",
        "\n",
        "    result = f\"# ðŸ”— Related to: {article['title']}\\n\\n\"\n",
        "    result += f\"**Relationship Type:** {relationship_type}\\n\"\n",
        "    result += f\"**Found:** {len(related)} related articles\\n\\n\"\n",
        "\n",
        "    for i, rel in enumerate(related, 1):\n",
        "        result += f\"## {i}. {rel['title']}\\n\"\n",
        "        result += f\"**Content ID:** {rel.get('content_id', 'unknown')}\\n\"\n",
        "        result += f\"**Similarity:** {rel['similarity']:.1%}\\n\"\n",
        "        result += f\"**Source:** {rel['source']}\\n\\n\"\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "004c56d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PROMPTS\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "@mcp.prompt()\n",
        "async def create_morning_brief() -> str:\n",
        "    \"\"\"Workflow for creating a quick morning newspaper (15-20min read).\"\"\"\n",
        "    return \"\"\"Create a focused morning tech brief (15-20min read)\n",
        "\n",
        "WORKFLOW:\n",
        "1. discover_stories(query=\"tech news today\", count=20, sources=[\"hn\"])\n",
        "   â†’ Review summaries, pick top stories\n",
        "\n",
        "2. create_newspaper(type=\"morning_brief\", title=f\"Morning Brief - {date}\")\n",
        "\n",
        "3. add_content_cluster(\n",
        "     newspaper_id,\n",
        "     section=\"Breaking News\",\n",
        "     content_ids=[top 3 content_ids],\n",
        "     treatment=\"brief\",\n",
        "     auto_enhance=True\n",
        "   )\n",
        "\n",
        "4. add_content_cluster(\n",
        "     newspaper_id,\n",
        "     section=\"Quick Reads\",\n",
        "     content_ids=[next 4-5 content_ids],\n",
        "     treatment=\"brief\"\n",
        "   )\n",
        "\n",
        "5. Optional: create_editorial_synthesis if themes emerge\n",
        "\n",
        "6. validate_and_finalize(\n",
        "     newspaper_id,\n",
        "     min_reading_time=15,\n",
        "     min_articles=5\n",
        "   )\n",
        "\n",
        "7. publish_newspaper(delivery_method=\"email\")\n",
        "\n",
        "TOOL CALLS: ~8-10\n",
        "AGENT CONTROLS: Which stories, editorial synthesis decision, final polish\"\"\"\n",
        "\n",
        "\n",
        "@mcp.prompt()\n",
        "async def create_deep_dive() -> str:\n",
        "    \"\"\"Workflow for comprehensive deep dive newspaper (30-45min read).\"\"\"\n",
        "    return \"\"\"Create comprehensive deep dive newspaper (30-45min read)\n",
        "\n",
        "WORKFLOW:\n",
        "1. discover_stories(query=\"tech\", count=30, sources=[\"hn\"])\n",
        "   â†’ Review enriched summaries with relevance scores\n",
        "\n",
        "2. Review resource: memory://context-summary\n",
        "   â†’ Check trending topics and coverage gaps\n",
        "\n",
        "3. Group stories by theme (use your judgment based on topics)\n",
        "\n",
        "4. create_newspaper(type=\"deep_dive\", title=\"Deep Dive: {themes}\")\n",
        "\n",
        "5. For each theme (3-4 themes):\n",
        "   a. add_content_cluster(\n",
        "        newspaper_id,\n",
        "        section=theme_name,\n",
        "        content_ids=[3-4 content_ids],\n",
        "        treatment=\"detailed\",\n",
        "        auto_enhance=True,\n",
        "        link_related=True\n",
        "      )\n",
        "      â†’ Tool handles: fetch, context, sampling, formatting\n",
        "\n",
        "   b. enhance_article(\n",
        "        newspaper_id,\n",
        "        section=theme_name,\n",
        "        article_title=lead_article,\n",
        "        add_pull_quote=True,\n",
        "        add_key_points=True\n",
        "      )\n",
        "      â†’ Extra polish for lead article\n",
        "\n",
        "   c. create_editorial_synthesis(\n",
        "        newspaper_id,\n",
        "        content_ids=theme_content_ids,\n",
        "        angle=\"analytical\",\n",
        "        placement=\"section_intro\"\n",
        "      )\n",
        "\n",
        "6. If themes connect:\n",
        "   add_editorial_element(\n",
        "     newspaper_id,\n",
        "     element_type=\"theme_highlight\",\n",
        "     generate=True,\n",
        "     generation_context=\"Connect cross-theme patterns\"\n",
        "   )\n",
        "\n",
        "7. validate_and_finalize(\n",
        "     newspaper_id,\n",
        "     min_reading_time=30,\n",
        "     min_articles=8\n",
        "   )\n",
        "   â†’ If fails: Get specific fixes, execute, re-validate\n",
        "\n",
        "8. publish_newspaper(delivery_method=\"both\")\n",
        "\n",
        "TOOL CALLS: ~20-25\n",
        "AGENT CONTROLS: Theme selection, lead articles, editorial angles, cross-theme synthesis\n",
        "DELEGATED: Content fetching, summarization, formatting, context inclusion\"\"\"\n",
        "\n",
        "\n",
        "@mcp.prompt()\n",
        "async def follow_story() -> str:\n",
        "    \"\"\"Follow up on story from past newspapers.\"\"\"\n",
        "    return \"\"\"Follow up on story from past newspapers\n",
        "\n",
        "WORKFLOW:\n",
        "1. search_context(query=topic, context_type=\"newspapers\")\n",
        "   â†’ Identify past coverage\n",
        "\n",
        "2. Read resource: memory://articles/{topic}\n",
        "   â†’ See all related past articles\n",
        "\n",
        "3. discover_stories(query=topic, count=15, sources=[\"hn\"])\n",
        "   â†’ Find new developments\n",
        "\n",
        "4. get_related_content(content_id=original_story, relationship_type=\"follow_up\")\n",
        "\n",
        "5. create_newspaper(\n",
        "     type=\"follow_up\",\n",
        "     title=f\"Follow-up: {topic}\",\n",
        "     structure_template=past_newspaper_id\n",
        "   )\n",
        "\n",
        "6. add_content_cluster(\n",
        "     newspaper_id,\n",
        "     section=\"What Changed\",\n",
        "     content_ids=new_developments,\n",
        "     treatment=\"detailed\"\n",
        "   )\n",
        "\n",
        "7. add_content_cluster(\n",
        "     newspaper_id,\n",
        "     section=\"Deep Analysis\",\n",
        "     content_ids=analysis_pieces,\n",
        "     treatment=\"technical\"\n",
        "   )\n",
        "\n",
        "8. create_editorial_synthesis(\n",
        "     newspaper_id,\n",
        "     content_ids=[all],\n",
        "     angle=\"forward-looking\",\n",
        "     placement=\"closing_thoughts\"\n",
        "   )\n",
        "\n",
        "9. validate_and_finalize + publish_newspaper\n",
        "\n",
        "TOOL CALLS: ~15-20\n",
        "AGENT CONTROLS: What's \"new\" vs rehash, comparative emphasis, predictions\"\"\"\n",
        "\n",
        "\n",
        "@mcp.prompt()\n",
        "async def interactive_research() -> str:\n",
        "    \"\"\"Interactive research with continuous user input.\"\"\"\n",
        "    return \"\"\"Interactive research session with elicitation\n",
        "\n",
        "WORKFLOW:\n",
        "1. Get topic from context or ask user\n",
        "\n",
        "2. search_context(query=topic) + memory://articles/{topic}\n",
        "   â†’ \"Here's what I already know\"\n",
        "\n",
        "3. discover_stories(query=topic, count=20)\n",
        "   â†’ Agent reviews, proposes focus areas\n",
        "\n",
        "4. Use elicitation in add_content_cluster for depth decisions\n",
        "\n",
        "5. For each focus area:\n",
        "   a. add_content_cluster (builds newspaper progressively)\n",
        "   b. Check if user wants to pivot or go deeper\n",
        "   c. get_related_content to expand coverage\n",
        "\n",
        "6. create_newspaper when sufficient coverage\n",
        "   a. Agent proposes structure based on exploration\n",
        "   b. Add all explored content with appropriate treatments\n",
        "   c. create_editorial_synthesis with chosen angle\n",
        "\n",
        "7. validate_and_finalize + publish_newspaper\n",
        "\n",
        "TOOL CALLS: Variable (user-driven)\n",
        "AGENT CONTROLS: Information synthesis, structure proposals\n",
        "USER CONTROLS (via elicitation): Direction, depth, when to finalize\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "da369b36",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "ðŸš€ ADVANCED NEWSPAPER AGENT MCP SERVER\n",
            "============================================================\n",
            "\n",
            "ðŸ“Š Server Statistics:\n",
            "  â€¢ Resources: 4 (interests, context summary, articles by topic, recent newspapers)\n",
            "  â€¢ Tools: 14 (discovery, creation, polish, quality, context)\n",
            "  â€¢ Prompts: 4 (morning brief, deep dive, follow story, research)\n",
            "\n",
            "âœ¨ Key Features:\n",
            "  â€¢ Smart composition - one tool does many operations\n",
            "  â€¢ Content IDs - clean references for agents\n",
            "  â€¢ Automatic context - interests & past coverage included\n",
            "  â€¢ Sampling - LLM generation for summaries & editorials\n",
            "  â€¢ Elicitation - interactive user choices\n",
            "  â€¢ Progress - real-time operation updates\n",
            "  â€¢ Quality enforcement - prevents low-quality newspapers\n",
            "\n",
            "============================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>                                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>    <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">    _ __ ___  _____           __  __  _____________    ____    ____ </span>    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>    <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">   _ __ ___ .'____/___ ______/ /_/  |/  / ____/ __ \\  |___ \\  / __ \\</span>    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>    <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">  _ __ ___ / /_  / __ `/ ___/ __/ /|_/ / /   / /_/ /  ___/ / / / / /</span>    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>    <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> _ __ ___ / __/ / /_/ (__  ) /_/ /  / / /___/ ____/  /  __/_/ /_/ / </span>    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>    <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">_ __ ___ /_/    \\____/____/\\__/_/  /_/\\____/_/      /_____(*)____/  </span>    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>                                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>                                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>                                <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">FastMCP  2.0</span>                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>                                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>                                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>               <span style=\"font-weight: bold\">ðŸ–¥ï¸  </span><span style=\"color: #008080; text-decoration-color: #008080\">Server name:     </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">advanced-newspaper-agent </span>                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>               <span style=\"font-weight: bold\">ðŸ“¦ </span><span style=\"color: #008080; text-decoration-color: #008080\">Transport:       </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Streamable-HTTP          </span>                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>               <span style=\"font-weight: bold\">ðŸ”— </span><span style=\"color: #008080; text-decoration-color: #008080\">Server URL:      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">http://127.0.0.1:8080/mcp</span>                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>               <span style=\"font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080\">                 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>               <span style=\"font-weight: bold\">ðŸŽï¸  </span><span style=\"color: #008080; text-decoration-color: #008080\">FastMCP version: </span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">2.12.3                   </span>                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>               <span style=\"font-weight: bold\">ðŸ¤ </span><span style=\"color: #008080; text-decoration-color: #008080\">MCP SDK version: </span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">1.14.1                   </span>                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>               <span style=\"font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080\">                 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>               <span style=\"font-weight: bold\">ðŸ“š </span><span style=\"color: #008080; text-decoration-color: #008080\">Docs:            </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">https://gofastmcp.com    </span>                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>               <span style=\"font-weight: bold\">ðŸš€ </span><span style=\"color: #008080; text-decoration-color: #008080\">Deploy:          </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">https://fastmcp.cloud    </span>                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>                                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚</span>\n",
              "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\n",
              "\u001b[2mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
              "\u001b[2mâ”‚\u001b[0m                                                                            \u001b[2mâ”‚\u001b[0m\n",
              "\u001b[2mâ”‚\u001b[0m    \u001b[1;32m    _ __ ___  _____           __  __  _____________    ____    ____ \u001b[0m    \u001b[2mâ”‚\u001b[0m\n",
              "\u001b[2mâ”‚\u001b[0m    \u001b[1;32m   _ __ ___ .'____/___ ______/ /_/  |/  / ____/ __ \\  |___ \\  / __ \\\u001b[0m    \u001b[2mâ”‚\u001b[0m\n",
              "\u001b[2mâ”‚\u001b[0m    \u001b[1;32m  _ __ ___ / /_  / __ `/ ___/ __/ /|_/ / /   / /_/ /  ___/ / / / / /\u001b[0m    \u001b[2mâ”‚\u001b[0m\n",
              "\u001b[2mâ”‚\u001b[0m    \u001b[1;32m _ __ ___ / __/ / /_/ (__  ) /_/ /  / / /___/ ____/  /  __/_/ /_/ / \u001b[0m    \u001b[2mâ”‚\u001b[0m\n",
              "\u001b[2mâ”‚\u001b[0m    \u001b[1;32m_ __ ___ /_/    \\____/____/\\__/_/  /_/\\____/_/      /_____(*)____/  \u001b[0m    \u001b[2mâ”‚\u001b[0m\n",
              "\u001b[2mâ”‚\u001b[0m                                                                            \u001b[2mâ”‚\u001b[0m\n",
              "\u001b[2mâ”‚\u001b[0m                                                                            \u001b[2mâ”‚\u001b[0m\n",
              "\u001b[2mâ”‚\u001b[0m                                \u001b[1;34mFastMCP  2.0\u001b[0m                                \u001b[2mâ”‚\u001b[0m\n",
              "\u001b[2mâ”‚\u001b[0m                                                                            \u001b[2mâ”‚\u001b[0m\n",
              "\u001b[2mâ”‚\u001b[0m                                                                            \u001b[2mâ”‚\u001b[0m\n",
              "\u001b[2mâ”‚\u001b[0m               \u001b[1mðŸ–¥ï¸ \u001b[0m\u001b[1m \u001b[0m\u001b[36mServer name:    \u001b[0m\u001b[36m \u001b[0m\u001b[2madvanced-newspaper-agent \u001b[0m                \u001b[2mâ”‚\u001b[0m\n",
              "\u001b[2mâ”‚\u001b[0m               \u001b[1mðŸ“¦\u001b[0m\u001b[1m \u001b[0m\u001b[36mTransport:      \u001b[0m\u001b[36m \u001b[0m\u001b[2mStreamable-HTTP          \u001b[0m                \u001b[2mâ”‚\u001b[0m\n",
              "\u001b[2mâ”‚\u001b[0m               \u001b[1mðŸ”—\u001b[0m\u001b[1m \u001b[0m\u001b[36mServer URL:     \u001b[0m\u001b[36m \u001b[0m\u001b[2mhttp://127.0.0.1:8080/mcp\u001b[0m                \u001b[2mâ”‚\u001b[0m\n",
              "\u001b[2mâ”‚\u001b[0m               \u001b[1m  \u001b[0m\u001b[1m \u001b[0m\u001b[36m                \u001b[0m\u001b[36m \u001b[0m\u001b[2m                         \u001b[0m                \u001b[2mâ”‚\u001b[0m\n",
              "\u001b[2mâ”‚\u001b[0m               \u001b[1mðŸŽï¸ \u001b[0m\u001b[1m \u001b[0m\u001b[36mFastMCP version:\u001b[0m\u001b[36m \u001b[0m\u001b[2;37m2.12.3                   \u001b[0m                \u001b[2mâ”‚\u001b[0m\n",
              "\u001b[2mâ”‚\u001b[0m               \u001b[1mðŸ¤\u001b[0m\u001b[1m \u001b[0m\u001b[36mMCP SDK version:\u001b[0m\u001b[36m \u001b[0m\u001b[2;37m1.14.1                   \u001b[0m                \u001b[2mâ”‚\u001b[0m\n",
              "\u001b[2mâ”‚\u001b[0m               \u001b[1m  \u001b[0m\u001b[1m \u001b[0m\u001b[36m                \u001b[0m\u001b[36m \u001b[0m\u001b[2m                         \u001b[0m                \u001b[2mâ”‚\u001b[0m\n",
              "\u001b[2mâ”‚\u001b[0m               \u001b[1mðŸ“š\u001b[0m\u001b[1m \u001b[0m\u001b[36mDocs:           \u001b[0m\u001b[36m \u001b[0m\u001b[2mhttps://gofastmcp.com    \u001b[0m                \u001b[2mâ”‚\u001b[0m\n",
              "\u001b[2mâ”‚\u001b[0m               \u001b[1mðŸš€\u001b[0m\u001b[1m \u001b[0m\u001b[36mDeploy:         \u001b[0m\u001b[36m \u001b[0m\u001b[2mhttps://fastmcp.cloud    \u001b[0m                \u001b[2mâ”‚\u001b[0m\n",
              "\u001b[2mâ”‚\u001b[0m                                                                            \u001b[2mâ”‚\u001b[0m\n",
              "\u001b[2mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10/08/25 16:00:51] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting MCP server <span style=\"color: #008000; text-decoration-color: #008000\">'advanced-newspaper-agent'</span> with transport           <a href=\"file:///Users/adi/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/fastmcp/server/server.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">server.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/adi/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/fastmcp/server/server.py#1572\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1572</span></a>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'streamable-http'</span> on <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">http://127.0.0.1:8080/mcp</span>                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[10/08/25 16:00:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting MCP server \u001b[32m'advanced-newspaper-agent'\u001b[0m with transport           \u001b]8;id=221284;file:///Users/adi/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/fastmcp/server/server.py\u001b\\\u001b[2mserver.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=823098;file:///Users/adi/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/fastmcp/server/server.py#1572\u001b\\\u001b[2m1572\u001b[0m\u001b]8;;\u001b\\\n",
              "\u001b[2;36m                    \u001b[0m         \u001b[32m'streamable-http'\u001b[0m on \u001b[4;94mhttp://127.0.0.1:8080/mcp\u001b[0m                          \u001b[2m              \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [86512]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8080 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Starting Advanced Newspaper Agent MCP Server\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10/08/25 16:00:55] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Article memory service initialized successfully                <a href=\"file:///Users/adi/Documents/GitHub/adi_mcp_server_trials/src/server/services/article_memory_v2.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">article_memory_v2.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/adi/Documents/GitHub/adi_mcp_server_trials/src/server/services/article_memory_v2.py#73\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">73</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[10/08/25 16:00:55]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Article memory service initialized successfully                \u001b]8;id=169198;file:///Users/adi/Documents/GitHub/adi_mcp_server_trials/src/server/services/article_memory_v2.py\u001b\\\u001b[2marticle_memory_v2.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=104287;file:///Users/adi/Documents/GitHub/adi_mcp_server_trials/src/server/services/article_memory_v2.py#73\u001b\\\u001b[2m73\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… All services initialized!\n",
            "INFO:     127.0.0.1:49637 - \"POST /mcp HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:49640 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49642 - \"GET /mcp HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:49651 - \"POST /mcp HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:49653 - \"POST /mcp HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:49655 - \"POST /mcp HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:49664 - \"POST /mcp HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:49667 - \"POST /mcp HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:49713 - \"POST /mcp HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10/08/25 16:01:45] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Created newspaper draft: newspaper_20251008_160145             <a href=\"file:///Users/adi/Documents/GitHub/adi_mcp_server_trials/src/server/services/newspaper_service.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">newspaper_service.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/adi/Documents/GitHub/adi_mcp_server_trials/src/server/services/newspaper_service.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[10/08/25 16:01:45]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Created newspaper draft: newspaper_20251008_160145             \u001b]8;id=349773;file:///Users/adi/Documents/GitHub/adi_mcp_server_trials/src/server/services/newspaper_service.py\u001b\\\u001b[2mnewspaper_service.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=648940;file:///Users/adi/Documents/GitHub/adi_mcp_server_trials/src/server/services/newspaper_service.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     127.0.0.1:49727 - \"POST /mcp HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:49731 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49735 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49739 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49743 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49750 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49753 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49757 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49761 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49767 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49772 - \"POST /mcp HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:49783 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49793 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49798 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49805 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49809 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49813 - \"POST /mcp HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:49822 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49827 - \"POST /mcp HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:49832 - \"POST /mcp HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:49854 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49858 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49865 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49871 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49876 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49883 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49886 - \"POST /mcp HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:49890 - \"POST /mcp HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:49896 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49899 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49904 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49907 - \"POST /mcp HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:49913 - \"POST /mcp HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:49930 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49933 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49937 - \"POST /mcp HTTP/1.1\" 202 Accepted\n",
            "INFO:     127.0.0.1:49942 - \"POST /mcp HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:49946 - \"POST /mcp HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10/08/25 16:06:22] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Newspaper sent successfully                                       <a href=\"file:///Users/adi/Documents/GitHub/adi_mcp_server_trials/src/server/services/email_service.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">email_service.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/adi/Documents/GitHub/adi_mcp_server_trials/src/server/services/email_service.py#115\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[10/08/25 16:06:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Newspaper sent successfully                                       \u001b]8;id=521497;file:///Users/adi/Documents/GitHub/adi_mcp_server_trials/src/server/services/email_service.py\u001b\\\u001b[2memail_service.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=259635;file:///Users/adi/Documents/GitHub/adi_mcp_server_trials/src/server/services/email_service.py#115\u001b\\\u001b[2m115\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Stored newspaper: newspaper_20251008_160145 <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> articles, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>  <a href=\"file:///Users/adi/Documents/GitHub/adi_mcp_server_trials/src/server/services/article_memory_v2.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">article_memory_v2.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/adi/Documents/GitHub/adi_mcp_server_trials/src/server/services/article_memory_v2.py#418\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">418</span></a>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         min<span style=\"font-weight: bold\">)</span>                                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Stored newspaper: newspaper_20251008_160145 \u001b[1m(\u001b[0m\u001b[1;36m12\u001b[0m articles, \u001b[1;36m16\u001b[0m  \u001b]8;id=329334;file:///Users/adi/Documents/GitHub/adi_mcp_server_trials/src/server/services/article_memory_v2.py\u001b\\\u001b[2marticle_memory_v2.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=391413;file:///Users/adi/Documents/GitHub/adi_mcp_server_trials/src/server/services/article_memory_v2.py#418\u001b\\\u001b[2m418\u001b[0m\u001b]8;;\u001b\\\n",
              "\u001b[2;36m                    \u001b[0m         min\u001b[1m)\u001b[0m                                                          \u001b[2m                        \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Shutting down\n",
            "ERROR:    Cancel 1 running task(s), timeout graceful shutdown exceeded\n",
            "INFO:     Waiting for application shutdown.\n",
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/adi/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "        self.scope, self.receive, self.send\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/adi/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/adi/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/starlette/applications.py\", line 113, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/Users/adi/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/Users/adi/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/fastmcp/server/http.py\", line 93, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/Users/adi/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/Users/adi/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/Users/adi/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/Users/adi/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/Users/adi/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/Users/adi/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/fastmcp/server/http.py\", line 37, in __call__\n",
            "    await self.session_manager.handle_request(scope, receive, send)\n",
            "  File \"/Users/adi/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/mcp/server/streamable_http_manager.py\", line 144, in handle_request\n",
            "    await self._handle_stateful_request(scope, receive, send)\n",
            "  File \"/Users/adi/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/mcp/server/streamable_http_manager.py\", line 216, in _handle_stateful_request\n",
            "    await transport.handle_request(scope, receive, send)\n",
            "  File \"/Users/adi/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/mcp/server/streamable_http.py\", line 286, in handle_request\n",
            "    await self._handle_get_request(request, send)\n",
            "  File \"/Users/adi/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/mcp/server/streamable_http.py\", line 593, in _handle_get_request\n",
            "    await response(request.scope, request.receive, send)\n",
            "  File \"/Users/adi/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/sse_starlette/sse.py\", line 255, in __call__\n",
            "    async with anyio.create_task_group() as task_group:\n",
            "               ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/adi/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 785, in __aexit__\n",
            "    raise exc_val\n",
            "  File \"/Users/adi/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 753, in __aexit__\n",
            "    await self._on_completed_fut\n",
            "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 286, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 375, in __wakeup\n",
            "    future.result()\n",
            "    ~~~~~~~~~~~~~^^\n",
            "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 194, in result\n",
            "    raise self._make_cancelled_error()\n",
            "asyncio.exceptions.CancelledError: Task cancelled, timeout graceful shutdown exceeded\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [86512]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ‘‹ Shutting down MCP Server\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m os.system(\u001b[33m\"\u001b[39m\u001b[33mlsof -ti:8080 | xargs kill -9 2>/dev/null\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Run server\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmcp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstreamable-http\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8080\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/nest_asyncio.py:92\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     90\u001b[39m     f._log_destroy_pending = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping:\n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/nest_asyncio.py:133\u001b[39m, in \u001b[36m_patch_loop.<locals>._run_once\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    130\u001b[39m curr_task = curr_tasks.pop(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[43mhandle\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    135\u001b[39m     \u001b[38;5;66;03m# restore the current task\u001b[39;00m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m curr_task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/events.py:89\u001b[39m, in \u001b[36mHandle._run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[32m     91\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:386\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    378\u001b[39m     \u001b[38;5;28mself\u001b[39m.__step(exc)\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    380\u001b[39m     \u001b[38;5;66;03m# Don't pass the value of `future.result()` explicitly,\u001b[39;00m\n\u001b[32m    381\u001b[39m     \u001b[38;5;66;03m# as `Future.__iter__` and `Future.__await__` don't need it.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    384\u001b[39m     \u001b[38;5;66;03m# instead of `__next__()`, which is slower for futures\u001b[39;00m\n\u001b[32m    385\u001b[39m     \u001b[38;5;66;03m# that return non-generator iterators from their `__iter__`.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:293\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(self, exc)\u001b[39m\n\u001b[32m    291\u001b[39m _enter_task(\u001b[38;5;28mself\u001b[39m._loop, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__step_run_and_handle_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    295\u001b[39m     _leave_task(\u001b[38;5;28mself\u001b[39m._loop, \u001b[38;5;28mself\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:304\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    302\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    303\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    306\u001b[39m         result = coro.throw(exc)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/fastmcp/server/server.py:358\u001b[39m, in \u001b[36mFastMCP.run_async\u001b[39m\u001b[34m(self, transport, show_banner, **transport_kwargs)\u001b[39m\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run_stdio_async(\n\u001b[32m    354\u001b[39m         show_banner=show_banner,\n\u001b[32m    355\u001b[39m         **transport_kwargs,\n\u001b[32m    356\u001b[39m     )\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m transport \u001b[38;5;129;01min\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mhttp\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msse\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstreamable-http\u001b[39m\u001b[33m\"\u001b[39m}:\n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run_http_async(\n\u001b[32m    359\u001b[39m         transport=transport,\n\u001b[32m    360\u001b[39m         show_banner=show_banner,\n\u001b[32m    361\u001b[39m         **transport_kwargs,\n\u001b[32m    362\u001b[39m     )\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    364\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown transport: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransport\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/fastmcp/server/server.py:1576\u001b[39m, in \u001b[36mFastMCP.run_http_async\u001b[39m\u001b[34m(self, show_banner, transport, host, port, log_level, path, uvicorn_config, middleware, stateless_http)\u001b[39m\n\u001b[32m   1571\u001b[39m path = app.state.path.lstrip(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m   1572\u001b[39m logger.info(\n\u001b[32m   1573\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStarting MCP server \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m with transport \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransport\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m on http://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mport\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1574\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1576\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m server.serve()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/uvicorn/server.py:70\u001b[39m, in \u001b[36mServer.serve\u001b[39m\u001b[34m(self, sockets)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mserve\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: \u001b[38;5;28mlist\u001b[39m[socket.socket] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcapture_signals\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mawait\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msockets\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:148\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    150\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/adi_mcp_server_trials/.venv/lib/python3.13/site-packages/uvicorn/server.py:331\u001b[39m, in \u001b[36mServer.capture_signals\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;66;03m# If we did gracefully shut down due to a signal, try to\u001b[39;00m\n\u001b[32m    328\u001b[39m \u001b[38;5;66;03m# trigger the expected behaviour now; multiple signals would be\u001b[39;00m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# done LIFO, see https://stackoverflow.com/questions/48434964\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m captured_signal \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m._captured_signals):\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     \u001b[43msignal\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_signal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcaptured_signal\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# SERVER STARTUP\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import warnings\n",
        "\n",
        "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"ðŸš€ ADVANCED NEWSPAPER AGENT MCP SERVER\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"\\nðŸ“Š Server Statistics:\")\n",
        "    print(\n",
        "        \"  â€¢ Resources: 4 (interests, context summary, articles by topic, recent newspapers)\"\n",
        "    )\n",
        "    print(\"  â€¢ Tools: 14 (discovery, creation, polish, quality, context)\")\n",
        "    print(\"  â€¢ Prompts: 4 (morning brief, deep dive, follow story, research)\")\n",
        "    print(\"\\nâœ¨ Key Features:\")\n",
        "    print(\"  â€¢ Smart composition - one tool does many operations\")\n",
        "    print(\"  â€¢ Content IDs - clean references for agents\")\n",
        "    print(\"  â€¢ Automatic context - interests & past coverage included\")\n",
        "    print(\"  â€¢ Sampling - LLM generation for summaries & editorials\")\n",
        "    print(\"  â€¢ Elicitation - interactive user choices\")\n",
        "    print(\"  â€¢ Progress - real-time operation updates\")\n",
        "    print(\"  â€¢ Quality enforcement - prevents low-quality newspapers\")\n",
        "    print(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
        "\n",
        "    # Kill any existing process on port 8080\n",
        "    os.system(\"lsof -ti:8080 | xargs kill -9 2>/dev/null\")\n",
        "\n",
        "    # Run server\n",
        "    asyncio.run(mcp.run_async(transport=\"streamable-http\", port=8080))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a75d8e8a",
      "metadata": {},
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "## Checkpoint 6 Results\n",
        "\n",
        "<img src=\"https://github.com/adityaarunsinghal/agentic-ai-workshop-2025/blob/main/notebooks/media/session02checkpoint06_newspaper.png?raw=true\" width=\"1500\" alt=\"session02checkpoint06_newspaper\">\n",
        "<!-- <img src=\"media/session02checkpoint06_newspaper.png\" width=\"1500\" alt=\"session02checkpoint06_newspaper\"> -->\n",
        "\n",
        "### Great newspaper!\n",
        "\n",
        "#### [ðŸ“„ Open Newspaper in Browser](https://htmlpreview.github.io/?https://github.com/adityaarunsinghal/agentic-ai-workshop-2025/blob/main/examples/newspaper_20251008_160145.html)\n",
        "\n",
        "<img src=\"https://github.com/adityaarunsinghal/agentic-ai-workshop-2025/blob/main/notebooks/media/session02checkpoint06_sampling_and_progress.png?raw=true\" width=\"1500\" alt=\"session02checkpoint06_sampling_and_progress\">\n",
        "<!-- <img src=\"media/session02checkpoint06_sampling_and_progress.png\" width=\"1500\" alt=\"session02checkpoint06_sampling_and_progress\"> -->\n",
        "\n",
        "### Very few tokens held in memory\n",
        "\n",
        "<br/>\n",
        "<img src=\"https://github.com/adityaarunsinghal/agentic-ai-workshop-2025/blob/main/notebooks/media/session02checkpoint06_low_tokens_held.png?raw=true\" width=\"1500\" alt=\"session02checkpoint06_low_tokens_held\">\n",
        "<!-- <img src=\"media/session02checkpoint06_low_tokens_held.png\" width=\"1500\" alt=\"session02checkpoint06_low_tokens_held\"> -->\n",
        "\n",
        "### \"Smart tools + Sampling\"\n",
        "\n",
        "_Mainline agent is not carrying around too many tokens but still has all the power_\n",
        "\n",
        "\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
